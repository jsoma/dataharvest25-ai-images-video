{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd14585",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade torch torchvision pillow sentence-transformers faiss-cpu pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jsoma/dataharvest25-ai-images-video/main/cat.png\"\n",
    "urllib.request.urlretrieve(url, \"cat.png\")\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jsoma/dataharvest25-ai-images-video/main/tattoos.zip\"\n",
    "urllib.request.urlretrieve(url, \"tattoos.zip\")\n",
    "\n",
    "with zipfile.ZipFile('tattoos.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c3778",
   "metadata": {},
   "source": [
    "# Image-based Semantic Search\n",
    "\n",
    "## aka searching by vibes\n",
    "\n",
    "When AI models \"think\" about a cat, they don't actually think about my adorable cats. They think about the *mathematical representation* of a cat.\n",
    "\n",
    "When multimodal models represent the *word* cat in their tiny electric brains, it's similar to when they represent an *image* of a cat. We can use this to build a **text search engine of images**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db577ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('clip-ViT-B-32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef169ae",
   "metadata": {},
   "source": [
    "Let's take this model and see what it thinks about when you tell it the word \"cat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043abb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.encode('cat')\n",
    "embedding[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425353d0",
   "metadata": {},
   "source": [
    "Ah, yes, sure, me too! And if we look at an image of a cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86763fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"cat.png\").convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e05932",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.encode('cat')\n",
    "embedding[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a008e23c",
   "metadata": {},
   "source": [
    "I'm not going to go through those numbers, but I guarantee they have some similarities!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757b8a7b",
   "metadata": {},
   "source": [
    "## Processing images\n",
    "\n",
    "So this becomes useful when you have a bunch of images and want to search through them. You create embeddings for your images, embed your search term, and then say \"find me all of the images that are kind of similar to this search term.\"\n",
    "\n",
    "We're going to use a collection of tattoo and non-tattoo images from a machine-learning project I did a few years ago. The process of building an embedding index works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "filenames = glob.glob(\"tattoos/*.jp*\")\n",
    "data = []\n",
    "\n",
    "embeddings = []\n",
    "for path in tqdm(filenames):\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    embedding = model.encode(image)\n",
    "    embeddings.append(embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc7dff",
   "metadata": {},
   "source": [
    "We're using [FAISS](https://github.com/facebookresearch/faiss) which is absolutely overkill, but oh well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf00581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embedding_matrix = np.vstack(embeddings).astype('float32')\n",
    "faiss.normalize_L2(embedding_matrix)\n",
    "\n",
    "index = faiss.IndexFlatIP(embedding_matrix.shape[1])\n",
    "index.add(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c935f",
   "metadata": {},
   "source": [
    "## Search by text\n",
    "\n",
    "To find images that match a text query, we just encode the text and say \"find me things that are similar!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae13521",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"colorful bird\"\n",
    "match_count = 10\n",
    "\n",
    "query_embedding = model.encode(query, convert_to_numpy=True).astype('float32')\n",
    "faiss.normalize_L2(query_embedding.reshape(1, -1))\n",
    "D, I = index.search(query_embedding.reshape(1, -1), match_count)\n",
    "\n",
    "matches = [filenames[i] for i in I[0]]\n",
    "scores = D[0]\n",
    "\n",
    "for filename, score in zip(matches, scores):\n",
    "    print(f\"{filename}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'scores': scores,\n",
    "    'filename': matches,\n",
    "    'query': query\n",
    "})\n",
    "df['preview'] = df['filename'].apply(lambda filename: f'<img src=\"{filename}\" width=\"100\"/>')\n",
    "\n",
    "\n",
    "HTML(df.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074fa63",
   "metadata": {},
   "source": [
    "## Search by image\n",
    "\n",
    "To find images that are similar to another image (with 'similar' having no true controllable meaning), we just encode the image and say \"find me things that are similar!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('tattoo.png').convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_count = 10\n",
    "\n",
    "query_embedding = model.encode(image, convert_to_numpy=True).astype('float32')\n",
    "faiss.normalize_L2(query_embedding.reshape(1, -1))\n",
    "D, I = index.search(query_embedding.reshape(1, -1), match_count)\n",
    "\n",
    "matches = [filenames[i] for i in I[0]]\n",
    "scores = D[0]\n",
    "\n",
    "for filename, score in zip(matches, scores):\n",
    "    print(f\"{filename}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703cfb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'scores': scores,\n",
    "    'filename': matches,\n",
    "})\n",
    "df['preview'] = df['filename'].apply(lambda filename: f'<img src=\"{filename}\" width=\"100\"/>')\n",
    "\n",
    "\n",
    "HTML(df.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e61617",
   "metadata": {},
   "source": [
    "Why are they similar? NO IDEA. *Because the model thinks so.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7712a3d7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
